{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marin\\anaconda3\\envs\\clust-arc\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\marin\\anaconda3\\envs\\clust-arc\\lib\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Users\\marin\\anaconda3\\envs\\clust-arc\\lib\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Users\\marin\\anaconda3\\envs\\clust-arc\\lib\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Users\\marin\\anaconda3\\envs\\clust-arc\\lib\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\marin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arxiv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import umap\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://export.arxiv.org/api/query?search_query=au:robert+koenig&cat:quant-ph&start=0&max_results=59'\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    soup = BeautifulSoup(response, \"lxml\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Locking of accessible information and implications for the security of\\n  quantum cryptography'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = soup.find_all('title')\n",
    "titles = list(map(lambda x:x.text, titles))\n",
    "del titles[0]\n",
    "\n",
    "titles[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  The unconditional security of a quantum key distribution protocol is often\\ndefined in terms of the accessible information, that is, the maximum mutual\\ninformation between the distributed key S and the outcome of an optimal\\nmeasurement on the adversary's (quantum) system. We show that, even if this\\nquantity is small, certain parts of the key S might still be completely\\ninsecure when S is used in applications, such as for one-time pad encryption.\\nThis flaw is due to a locking property of the accessible information: one\\nadditional (physical) bit of information might increase the accessible\\ninformation by more than one bit.\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries = soup.find_all('summary')\n",
    "summaries = list(map(lambda x:x.text, summaries))\n",
    "summaries[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33, 15]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_name(name):\n",
    "    split_name = name.split(' ', 1)\n",
    "    return True if split_name[0] == \"Robert\" or split_name[1] == \"Koenig\" else False\n",
    "\n",
    "names = soup.find_all('name')\n",
    "names = list(map(lambda x:x.text, names))\n",
    "names = list(filter(retrieve_name, names))\n",
    "del names[names.index('Robert Howe')]\n",
    "\n",
    "indices = list([names.index('Alexander Koenig'), names.index('Robert A. Bridges')])\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_to_remove = list()\n",
    "summaries_to_remove = list()\n",
    "\n",
    "for index in indices:\n",
    "    titles_to_remove.append(titles[index])\n",
    "    summaries_to_remove.append(summaries[index])\n",
    "    \n",
    "for title, summary in zip(titles_to_remove, summaries_to_remove):\n",
    "    titles.remove(title)\n",
    "    summaries.remove(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "koenig_papers = list()\n",
    "for title, summary in zip(titles, summaries):\n",
    "    koenig_papers.append(title + '.' + '\\n\\n' + summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The conditional entropy power inequality for Gaussian quantum states.\n",
      "\n",
      "  We propose a generalization of the quantum entropy power inequality involving\n",
      "conditional entropies. For the special case of Gaussian states, we give a proof\n",
      "based on perturbation theory for symplectic spectra. We discuss some\n",
      "implications for entanglement-assisted classical communication over additive\n",
      "bosonic noise channels.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(koenig_papers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(koenig_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = arxiv.Search(query = \"quantum\", max_results=350, sort_by=arxiv.SortCriterion.SubmittedDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = list()\n",
    "for result in search.results():\n",
    "    papers.append(result.title + '.' + '\\n\\n' + result.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Encoding For Healthcare Data Democratisation and Information Leakage Prevention.\n",
      "\n",
      "The lack of data democratization and information leakage from trained models\n",
      "hinder the development and acceptance of robust deep learning-based healthcare\n",
      "solutions. This paper argues that irreversible data encoding can provide an\n",
      "effective solution to achieve data democratization without violating the\n",
      "privacy constraints imposed on healthcare data and clinical models. An ideal\n",
      "encoding framework transforms the data into a new space where it is\n",
      "imperceptible to a manual or computational inspection. However, encoded data\n",
      "should preserve the semantics of the original data such that deep learning\n",
      "models can be trained effectively. This paper hypothesizes the characteristics\n",
      "of the desired encoding framework and then exploits random projections and\n",
      "random quantum encoding to realize this framework for dense and longitudinal or\n",
      "time-series data. Experimental evaluation highlights that models trained on\n",
      "encoded time-series data effectively uphold the information bottleneck\n",
      "principle and hence, exhibit lesser information leakage from trained models.\n"
     ]
    }
   ],
   "source": [
    "print(papers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize text into sentences\n",
    "tokenized_papers = [nltk.sent_tokenize(paper) for paper in papers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Encoding For Healthcare Data Democratisation and Information Leakage Prevention.',\n",
       " 'The lack of data democratization and information leakage from trained models\\nhinder the development and acceptance of robust deep learning-based healthcare\\nsolutions.',\n",
       " 'This paper argues that irreversible data encoding can provide an\\neffective solution to achieve data democratization without violating the\\nprivacy constraints imposed on healthcare data and clinical models.',\n",
       " 'An ideal\\nencoding framework transforms the data into a new space where it is\\nimperceptible to a manual or computational inspection.',\n",
       " 'However, encoded data\\nshould preserve the semantics of the original data such that deep learning\\nmodels can be trained effectively.',\n",
       " 'This paper hypothesizes the characteristics\\nof the desired encoding framework and then exploits random projections and\\nrandom quantum encoding to realize this framework for dense and longitudinal or\\ntime-series data.',\n",
       " 'Experimental evaluation highlights that models trained on\\nencoded time-series data effectively uphold the information bottleneck\\nprinciple and hence, exhibit lesser information leakage from trained models.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_papers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Encoding For Healthcare Data Democratisation and Information Leakage Prevention.\\n\\nThe lack of data democratization and information leakage from trained models\\nhinder the development and acceptance of robust deep learning-based healthcare\\nsolutions. This paper argues that irreversible data encoding can provide an\\neffective solution to achieve data democratization without violating the\\nprivacy constraints imposed on healthcare data and clinical models. An ideal\\nencoding framework transforms the data into a new space where it is\\nimperceptible to a manual or computational inspection. However, encoded data\\nshould preserve the semantics of the original data such that deep learning\\nmodels can be trained effectively. This paper hypothesizes the characteristics\\nof the desired encoding framework and then exploits random projections and\\nrandom quantum encoding to realize this framework for dense and longitudinal or\\ntime-series data. Experimental evaluation highlights that models trained on\\nencoded time-series data effectively uphold the information bottleneck\\nprinciple and hence, exhibit lesser information leakage from trained models.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of sentences in each paper\n",
    "num_sentences = [len(paper) for paper in tokenized_papers]\n",
    "num_sentences[0]\n",
    "\n",
    "# remove papers with less than 2 sentences\n",
    "for i in range(len(papers)):\n",
    "    if num_sentences[i] <= 3: # 1 title + 2 sentences \n",
    "        papers.remove(papers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_papers = [nltk.sent_tokenize(paper) for paper in papers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Encoding For Healthcare Data Democratisation and Information Leakage Prevention.',\n",
       " 'The lack of data democratization and information leakage from trained models\\nhinder the development and acceptance of robust deep learning-based healthcare\\nsolutions.',\n",
       " 'This paper argues that irreversible data encoding can provide an\\neffective solution to achieve data democratization without violating the\\nprivacy constraints imposed on healthcare data and clinical models.',\n",
       " 'An ideal\\nencoding framework transforms the data into a new space where it is\\nimperceptible to a manual or computational inspection.',\n",
       " 'However, encoded data\\nshould preserve the semantics of the original data such that deep learning\\nmodels can be trained effectively.',\n",
       " 'This paper hypothesizes the characteristics\\nof the desired encoding framework and then exploits random projections and\\nrandom quantum encoding to realize this framework for dense and longitudinal or\\ntime-series data.',\n",
       " 'Experimental evaluation highlights that models trained on\\nencoded time-series data effectively uphold the information bottleneck\\nprinciple and hence, exhibit lesser information leakage from trained models.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_papers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = list()\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "for token_paper in tokenized_papers:\n",
    "    embeddings.append(model.encode(token_paper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Making Atomic-Level Magnetism Tunable with Light at Room Temperature.',\n",
       " 'The capacity to manipulate magnetization in two-dimensional dilute magnetic\\nsemiconductors (2D-DMSs) using light, specifically in magnetically doped\\ntransition metal dichalcogenide (TMD) monolayers (M-doped TX2, where M = V, Fe,\\nCr; T = W, Mo; X = S, Se, Te), may lead to innovative applications in\\nspintronics, spin-caloritronics, valleytronics, and quantum computation.',\n",
       " 'This\\nPerspective paper explores the mediation of magnetization by light under\\nambient conditions in 2D-TMD DMSs and heterostructures.',\n",
       " 'By combining magneto-LC\\nresonance (MLCR) experiments with density functional theory (DFT) calculations,\\nwe show that the magnetization can be enhanced using light in V-doped TMD\\nmonolayers (e.g., V-WS2, V-WSe2, V-MoS2).',\n",
       " 'This phenomenon is attributed to\\nexcess holes in the conduction and valence bands, as well as carriers trapped\\nin magnetic doping states, which together mediate the magnetization of the\\nsemiconducting layer.',\n",
       " 'In 2D-TMD heterostructures such as VSe2/WS2 and\\nVSe2/MoS2, we demonstrate the significance of proximity, charge-transfer, and\\nconfinement effects in amplifying light-mediated magnetism.',\n",
       " 'This effect is\\nattributed to photon absorption at the TMD layer (e.g., WS2, MoS2) that\\ngenerates electron-hole pairs mediating the magnetization of the\\nheterostructure.',\n",
       " 'These findings will encourage further research in the field of\\n2D magnetism and establish a novel direction for designing 2D-TMDs and\\nheterostructures with optically tunable magnetic functionalities, paving the\\nway for next-generation magneto-optic nanodevices.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmin([embedding.shape[0] for embedding in embeddings])\n",
    "tokenized_papers[335]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marin\\anaconda3\\envs\\clust-arc\\lib\\site-packages\\umap\\umap_.py:2344: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n",
      "c:\\Users\\marin\\anaconda3\\envs\\clust-arc\\lib\\site-packages\\umap\\umap_.py:132: UserWarning: A large number of your vertices were disconnected from the manifold.\n",
      "Disconnection_distance = inf has removed 0 edges.\n",
      "It has fully disconnected 2 vertices.\n",
      "You might consider using find_disconnected_points() to find and remove these points from your data.\n",
      "Use umap.utils.disconnected_vertices() to identify them.\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\marin\\Desktop\\Github\\Clustering-Archive\\clustering.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marin/Desktop/Github/Clustering-Archive/clustering.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m reducer \u001b[39m=\u001b[39m umap\u001b[39m.\u001b[39mUMAP(n_neighbors\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, init\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrandom\u001b[39m\u001b[39m'\u001b[39m, n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/marin/Desktop/Github/Clustering-Archive/clustering.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m umap_embeddings\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(\u001b[39mlambda\u001b[39;49;00m x:reducer\u001b[39m.\u001b[39;49mfit_transform(x), embeddings))\n",
      "\u001b[1;32mc:\\Users\\marin\\Desktop\\Github\\Clustering-Archive\\clustering.ipynb Cell 16\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marin/Desktop/Github/Clustering-Archive/clustering.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m reducer \u001b[39m=\u001b[39m umap\u001b[39m.\u001b[39mUMAP(n_neighbors\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, init\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrandom\u001b[39m\u001b[39m'\u001b[39m, n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/marin/Desktop/Github/Clustering-Archive/clustering.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m umap_embeddings\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x:reducer\u001b[39m.\u001b[39;49mfit_transform(x), embeddings))\n",
      "File \u001b[1;32mc:\\Users\\marin\\anaconda3\\envs\\clust-arc\\lib\\site-packages\\umap\\umap_.py:2772\u001b[0m, in \u001b[0;36mUMAP.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   2742\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2743\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit X into an embedded space and return that transformed\u001b[39;00m\n\u001b[0;32m   2744\u001b[0m \u001b[39m    output.\u001b[39;00m\n\u001b[0;32m   2745\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2770\u001b[0m \u001b[39m        Local radii of data points in the embedding (log-transformed).\u001b[39;00m\n\u001b[0;32m   2771\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2772\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[0;32m   2773\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   2774\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_dens:\n",
      "File \u001b[1;32mc:\\Users\\marin\\anaconda3\\envs\\clust-arc\\lib\\site-packages\\umap\\umap_.py:2684\u001b[0m, in \u001b[0;36mUMAP.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   2681\u001b[0m     \u001b[39mprint\u001b[39m(ts(), \u001b[39m\"\u001b[39m\u001b[39mConstruct embedding\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 2684\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_, aux_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_embed_data(\n\u001b[0;32m   2685\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_data[index],\n\u001b[0;32m   2686\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_epochs,\n\u001b[0;32m   2687\u001b[0m         init,\n\u001b[0;32m   2688\u001b[0m         random_state,  \u001b[39m# JH why raw data?\u001b[39;49;00m\n\u001b[0;32m   2689\u001b[0m     )\n\u001b[0;32m   2690\u001b[0m     \u001b[39m# Assign any points that are fully disconnected from our manifold(s) to have embedding\u001b[39;00m\n\u001b[0;32m   2691\u001b[0m     \u001b[39m# coordinates of np.nan.  These will be filtered by our plotting functions automatically.\u001b[39;00m\n\u001b[0;32m   2692\u001b[0m     \u001b[39m# They also prevent users from being deceived a distance query to one of these points.\u001b[39;00m\n\u001b[0;32m   2693\u001b[0m     \u001b[39m# Might be worth moving this into simplicial_set_embedding or _fit_embed_data\u001b[39;00m\n\u001b[0;32m   2694\u001b[0m     disconnected_vertices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph_\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mflatten() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\marin\\anaconda3\\envs\\clust-arc\\lib\\site-packages\\umap\\umap_.py:2717\u001b[0m, in \u001b[0;36mUMAP._fit_embed_data\u001b[1;34m(self, X, n_epochs, init, random_state)\u001b[0m\n\u001b[0;32m   2713\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit_embed_data\u001b[39m(\u001b[39mself\u001b[39m, X, n_epochs, init, random_state):\n\u001b[0;32m   2714\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"A method wrapper for simplicial_set_embedding that can be\u001b[39;00m\n\u001b[0;32m   2715\u001b[0m \u001b[39m    replaced by subclasses.\u001b[39;00m\n\u001b[0;32m   2716\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2717\u001b[0m     \u001b[39mreturn\u001b[39;00m simplicial_set_embedding(\n\u001b[0;32m   2718\u001b[0m         X,\n\u001b[0;32m   2719\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph_,\n\u001b[0;32m   2720\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_components,\n\u001b[0;32m   2721\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initial_alpha,\n\u001b[0;32m   2722\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_a,\n\u001b[0;32m   2723\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_b,\n\u001b[0;32m   2724\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepulsion_strength,\n\u001b[0;32m   2725\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnegative_sample_rate,\n\u001b[0;32m   2726\u001b[0m         n_epochs,\n\u001b[0;32m   2727\u001b[0m         init,\n\u001b[0;32m   2728\u001b[0m         random_state,\n\u001b[0;32m   2729\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_distance_func,\n\u001b[0;32m   2730\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_metric_kwds,\n\u001b[0;32m   2731\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdensmap,\n\u001b[0;32m   2732\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_densmap_kwds,\n\u001b[0;32m   2733\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_dens,\n\u001b[0;32m   2734\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_output_distance_func,\n\u001b[0;32m   2735\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_output_metric_kwds,\n\u001b[0;32m   2736\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_metric \u001b[39min\u001b[39;49;00m (\u001b[39m\"\u001b[39;49m\u001b[39meuclidean\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39ml2\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   2737\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   2738\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   2739\u001b[0m         tqdm_kwds\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtqdm_kwds,\n\u001b[0;32m   2740\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\marin\\anaconda3\\envs\\clust-arc\\lib\\site-packages\\umap\\umap_.py:1066\u001b[0m, in \u001b[0;36msimplicial_set_embedding\u001b[1;34m(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, densmap, densmap_kwds, output_dens, output_metric, output_metric_kwds, euclidean_output, parallel, verbose, tqdm_kwds)\u001b[0m\n\u001b[0;32m   1063\u001b[0m     n_epochs \u001b[39m=\u001b[39m default_epochs\n\u001b[0;32m   1065\u001b[0m \u001b[39mif\u001b[39;00m n_epochs \u001b[39m>\u001b[39m \u001b[39m10\u001b[39m:\n\u001b[1;32m-> 1066\u001b[0m     graph\u001b[39m.\u001b[39mdata[graph\u001b[39m.\u001b[39mdata \u001b[39m<\u001b[39m (graph\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mmax() \u001b[39m/\u001b[39m \u001b[39mfloat\u001b[39m(n_epochs))] \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m   1067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1068\u001b[0m     graph\u001b[39m.\u001b[39mdata[graph\u001b[39m.\u001b[39mdata \u001b[39m<\u001b[39m (graph\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mmax() \u001b[39m/\u001b[39m \u001b[39mfloat\u001b[39m(default_epochs))] \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\marin\\anaconda3\\envs\\clust-arc\\lib\\site-packages\\numpy\\core\\_methods.py:41\u001b[0m, in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_amax\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     40\u001b[0m           initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_maximum(a, axis, \u001b[39mNone\u001b[39;49;00m, out, keepdims, initial, where)\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "reducer = umap.UMAP(n_neighbors=2, init='random', n_components=2)\n",
    "umap_embeddings=list(map(lambda x:reducer.fit_transform(x), embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
